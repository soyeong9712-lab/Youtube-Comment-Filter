# ==============================
# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
# ==============================
import os
from dotenv import load_dotenv
load_dotenv()

# ==============================
# YouTube API ë¼ì´ë¸ŒëŸ¬ë¦¬
# ==============================
from googleapiclient.discovery import build

# ==============================
# OpenAI ëŒ“ê¸€ ë¶„ì„ í•¨ìˆ˜
# ==============================
# â— 1ìˆœìœ„ ê°œì„  í¬ì¸íŠ¸:
# - analyze_comment ë‚´ë¶€ GPT í”„ë¡¬í”„íŠ¸ë¥¼
#   "í™•ì‹¤í•  ë•Œë§Œ ìœ„í—˜" ê¸°ì¤€ìœ¼ë¡œ ì™„í™”í•´ì•¼ í•¨
from backend.openai_service import analyze_comment


# ==============================
# DB ì €ì¥ ëª¨ë“ˆ
# ==============================
from backend.database import (
    save_video_with_comments, 
    init_database,
    save_video,
    save_user,
    save_comment_and_analysis
)

# ==============================
# YouTube API Key
# ==============================
YOUTUBE_API_KEY = os.getenv("YOUTUBE_API_KEY")

# â— API í‚¤ ì—†ì„ ë•Œ ë°”ë¡œ ì—ëŸ¬ í™•ì¸ìš©
if not YOUTUBE_API_KEY:
    raise ValueError("YOUTUBE_API_KEYê°€ .envì— ì—†ìŠµë‹ˆë‹¤.")

# ==============================
# YouTube Data API ê°ì²´ ìƒì„±
# ==============================
youtube = build(
    "youtube",
    "v3",
    developerKey=YOUTUBE_API_KEY
)

def get_video_info(video_id):
    """
    YouTube ë¹„ë””ì˜¤ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    
    Returns:
        Dict: {
            'video_id': str,
            'title': str,
            'channel_name': str,
            'channel_id': str,
            'view_count': int,
            'like_count': int,
            'comment_count': int,
            'published_at': str,
            'description': str,
            'thumbnail_url': str
        }
    """
    try:
        request = youtube.videos().list(
            part="snippet,statistics",
            id=video_id
        )
        response = request.execute()
        
        if not response.get("items"):
            raise ValueError(f"ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_id}")
        
        item = response["items"][0]
        snippet = item["snippet"]
        statistics = item.get("statistics", {})
        
        thumbnails = snippet.get("thumbnails", {})
        thumbnail_url = ""
        if thumbnails.get("high"):
            thumbnail_url = thumbnails["high"]["url"]
        elif thumbnails.get("medium"):
            thumbnail_url = thumbnails["medium"]["url"]
        elif thumbnails.get("default"):
            thumbnail_url = thumbnails["default"]["url"]
        
        return {
            "video_id": video_id,
            "title": snippet.get("title", ""),
            "channel_name": snippet.get("channelTitle", ""),
            "channel_id": snippet.get("channelId", ""),
            "view_count": int(statistics.get("viewCount", 0)),
            "like_count": int(statistics.get("likeCount", 0)),
            "comment_count": int(statistics.get("commentCount", 0)),
            "published_at": snippet.get("publishedAt", ""),
            "description": snippet.get("description", ""),
            "thumbnail_url": thumbnail_url
        }
    except Exception as e:
        print(f"âš ï¸ ë¹„ë””ì˜¤ ì •ë³´ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
        raise


def get_comments(video_id, max_results=50):
    """
    ìœ íŠœë¸Œ ëŒ“ê¸€ì„ ê°€ì ¸ì™€ì„œ
    ê° ëŒ“ê¸€ì„ OpenAI(GPT)ë¡œ ë¶„ì„í•œ ë’¤ ë°˜í™˜

    âœ” max_results: ìµœëŒ€ë¡œ ê°€ì ¸ì˜¬ ëŒ“ê¸€ ìˆ˜ (50, 100, 200 ë“±)

    âš ï¸ ì£¼ì˜:
    - YouTube APIëŠ” í•œ ë²ˆì— ìµœëŒ€ 50ê°œë§Œ ë°˜í™˜
    - nextPageTokenìœ¼ë¡œ ë°˜ë³µ í˜¸ì¶œ í•„ìš”
    """

    results = []        # í”„ë¡ íŠ¸ì—”ë“œìš© ê°„ë‹¨í•œ í˜•ì‹
    db_comments = []    # DB ì €ì¥ìš© ìƒì„¸ í˜•ì‹
    page_token = None   # ğŸ”¥ í˜ì´ì§€ë„¤ì´ì…˜ìš© í† í°

    danger_count = 0    # ğŸ”¥ ìœ„í—˜ ëŒ“ê¸€ ê°œìˆ˜ (ìš”ì•½ìš©)

    # ==============================
    # ğŸ” nextPageTokenì´ ìˆëŠ” ë™ì•ˆ ë°˜ë³µ í˜¸ì¶œ
    # ==============================
    while len(results) < max_results:

        request = youtube.commentThreads().list(
            part="snippet",
            videoId=video_id,
            maxResults=50,            # â— YouTube API ìµœëŒ€ê°’ì€ í•­ìƒ 50
            textFormat="plainText",
            pageToken=page_token      # ğŸ”¥ ë‹¤ìŒ í˜ì´ì§€ ìš”ì²­
        )

        response = request.execute()

        # ==============================
        # ëŒ“ê¸€ í•˜ë‚˜ì”© ì²˜ë¦¬
        # ==============================
        for item in response.get("items", []):
            top_comment = item["snippet"]["topLevelComment"]
            snippet = top_comment["snippet"]
            text = snippet["textDisplay"]
            youtube_comment_id = top_comment["id"]
            author_id = snippet.get("authorChannelId", {}).get("value", "")
            
            # authorChannelIdê°€ ì—†ìœ¼ë©´ authorDisplayNameì„ í•´ì‹œí•´ì„œ ì‚¬ìš©
            if not author_id:
                import hashlib
                author_id = hashlib.md5(snippet["authorDisplayName"].encode()).hexdigest()

            # =====================================================
            # ğŸ”¥ OpenAI(GPT)ë¡œ ëŒ“ê¸€ ë¶„ì„
            # =====================================================
            analysis = analyze_comment(text)

            # ==============================
            # ğŸ”¥ category ì •ê·œí™” (ë§¤ìš° ì¤‘ìš”)
            # ==============================
            raw_category = analysis.get("category", "ì •ìƒ")

            # GPTê°€ ì´ìƒí•œ ê°’ ì£¼ë©´ ë¬´ì¡°ê±´ ì •ìƒ ì²˜ë¦¬
            if raw_category not in ["ì •ìƒ", "ìœ„í—˜", "ìš•ì„¤", "í˜ì˜¤", "ê´‘ê³ "]:
                raw_category = "ì •ìƒ"

            if raw_category == "ìœ„í—˜":
                danger_count += 1

            # í”„ë¡ íŠ¸ì—”ë“œìš© ê°„ë‹¨í•œ í˜•ì‹ (ê¸°ì¡´ í˜¸í™˜ì„± ìœ ì§€)
            results.append({
                "author": snippet["authorDisplayName"],
                "text": text,
                "likeCount": snippet["likeCount"],
                "publishedAt": snippet["publishedAt"],
                "category": raw_category,
                "reason": analysis.get("reason", "ë¶„ì„ ì‹¤íŒ¨ ë˜ëŠ” ê¸°ë³¸ ì²˜ë¦¬")
            })
            
            # DB ì €ì¥ìš© ìƒì„¸ ì •ë³´
            db_comments.append({
                "user": {
                    "user_id": author_id,
                    "username": snippet["authorDisplayName"],
                    "profile_image_url": snippet.get("authorProfileImageUrl", "")
                },
                "comment": {
                    "youtube_comment_id": youtube_comment_id,
                    "user_id": author_id,
                    "comment_text": text,
                    "like_count": snippet["likeCount"],
                    "reply_count": item["snippet"].get("totalReplyCount", 0),
                    "published_at": snippet["publishedAt"],
                    "parent_comment_id": None,
                    "is_reply": False
                },
                "analysis": {
                    "category": raw_category,
                    "reason": analysis.get("reason", ""),
                    "confidence_score": 0.8
                }
            })

            # â— max_results ì´ˆê³¼ ë°©ì§€
            if len(results) >= max_results:
                break

        # ==============================
        # ë‹¤ìŒ í˜ì´ì§€ í† í° ì²˜ë¦¬
        # ==============================
        page_token = response.get("nextPageToken")

        # â— ë‹¤ìŒ í˜ì´ì§€ ì—†ìœ¼ë©´ ì¢…ë£Œ
        if not page_token:
            break

    # ==============================
    # ğŸ”¥ ë¹„ë””ì˜¤ ì •ë³´ ê°€ì ¸ì˜¤ê¸° ë° DB ì €ì¥
    # ==============================
    try:
        video_info = get_video_info(video_id)
        
        # DBì— ì €ì¥
        stats = save_video_with_comments(video_info, db_comments)
        print(f"âœ… DB ì €ì¥ ì™„ë£Œ - ë¹„ë””ì˜¤: {stats['videos']}, ì‚¬ìš©ì: {stats['users']}, ëŒ“ê¸€: {stats['comments']}, ë¶„ì„: {stats['analyses']}")
    except Exception as e:
        print(f"âš ï¸ DB ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ê³„ì† ì§„í–‰): {e}")

    # ==============================
    # ğŸ”¥ ìš”ì•½ ì •ë³´ í¬í•¨í•´ì„œ ë°˜í™˜
    # ==============================
    return {
        "video_info": video_info,  # â­ ì´ ì¤„ì„ ë°˜ë“œì‹œ ì¶”ê°€í•˜ì„¸ìš”!
        "summary": {
            "total": len(results),
            "danger": danger_count
        },
        "comments": results
    }
